{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. AUTO DATA: OVERFITTING\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducing the Data\n",
    "\n",
    "**Note**: The `mpg` column is our target column and is the one we want to predict using the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
       "\n",
       "   model year  origin                   car name  \n",
       "0          70       1  chevrolet chevelle malibu  \n",
       "1          70       1          buick skylark 320  \n",
       "2          70       1         plymouth satellite  \n",
       "3          70       1              amc rebel sst  \n",
       "4          70       1                ford torino  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", 99)\n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option('precision', 3)\n",
    "\n",
    "cols = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \n",
    "        \"acceleration\", \"model year\", \"origin\", \"car name\"]\n",
    "cars = pd.read_csv('data/auto_mpg.data',\n",
    "                    delim_whitespace=True,\n",
    "                    names=cols)\n",
    "filtered_cars = cars[cars['horsepower'] != '?'].copy()\n",
    "filtered_cars['horsepower'] = filtered_cars['horsepower'].astype('float')\n",
    "print(filtered_cars.shape)\n",
    "filtered_cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bias-Variance Tradeoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.02017956815553 36.74255887416017\n",
      "18.6766165974193 42.08612184489641\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_and_test(cols):    \n",
    "    features = filtered_cars[cols]\n",
    "    target = filtered_cars[\"mpg\"]\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(features, target)\n",
    "    \n",
    "    predictions = lr.predict(features)\n",
    "   \n",
    "    mse = mean_squared_error(filtered_cars[\"mpg\"], predictions)\n",
    "    variance = np.var(predictions)\n",
    "    return(mse, variance)\n",
    "    \n",
    "cyl_mse, cyl_var = train_and_test([\"cylinders\"])\n",
    "weight_mse, weight_var = train_and_test([\"weight\"])\n",
    "print(cyl_mse, cyl_var)\n",
    "print(weight_mse, weight_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multivariate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.282057055586364 39.480681386729316\n",
      "20.252954839714228 40.509783602601445\n",
      "17.763860571843846 42.99887787047185\n",
      "17.76139610540622 43.001342336909396\n",
      "11.590170981415227 49.172567460900346\n",
      "10.847480945000454 49.915257497315146\n"
     ]
    }
   ],
   "source": [
    "two_mse, two_var = train_and_test(\n",
    "    [\"cylinders\", \"displacement\"])\n",
    "three_mse, three_var = train_and_test(\n",
    "    [\"cylinders\", \"displacement\", \"horsepower\"])\n",
    "four_mse, four_var = train_and_test(\n",
    "    [\"cylinders\", \"displacement\", \"horsepower\", \"weight\"])\n",
    "five_mse, five_var = train_and_test(\n",
    "    [\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \n",
    "     \"acceleration\"])\n",
    "six_mse, six_var = train_and_test(\n",
    "    [\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \n",
    "     \"acceleration\", \"model year\"])\n",
    "seven_mse, seven_var = train_and_test(\n",
    "    [\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \n",
    "     \"acceleration\",\"model year\", \"origin\"])\n",
    "\n",
    "print(two_mse, two_var)\n",
    "print(three_mse, three_var)\n",
    "print(four_mse, four_var)\n",
    "print(five_mse, five_var)\n",
    "print(six_mse, six_var)\n",
    "print(seven_mse, seven_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-Validation\n",
    "- A good way to detect if your model is overfitting is to compare the `in-sample error` and the `out-of-sample error`, or the training error with the test error. So far, we calculated the in sample error by testing the model over the same data it was trained on. To calculate the out-of-sample error, we need to test the data on a test set of data. We unfortunately don't have a separate test dataset and we'll instead use cross validation.\n",
    "- If a model's cross validation error (out-of-sample error) is much higher than the in sample error, then your data science senses should start to tingle. This is the first line of defense against overfitting and is a clear indicator that the trained model doesn't generalize well outside of the training set.\n",
    "- Let's create a new function to handle performing the cross validation and computing the cross validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.584370274954374 38.902525313756016\n",
      "20.655622193882955 40.091287956606934\n",
      "18.169683239081884 42.50764364364439\n",
      "18.283038517172052 42.59873630014678\n",
      "12.099685425467118 48.92824696771803\n",
      "11.418131971812054 49.90431373098729\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def train_and_cross_val(cols):\n",
    "    features = filtered_cars[cols]\n",
    "    target = filtered_cars[\"mpg\"]\n",
    "    \n",
    "    variance_values = []\n",
    "    mse_values = []\n",
    "    \n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=3)    \n",
    "    \n",
    "    for train_index, test_index in kf.split(features):        \n",
    "        X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "        y_train, y_test = target.iloc[train_index], target.iloc[test_index]        \n",
    "        \n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        predictions = lr.predict(X_test)        \n",
    "        \n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        var = np.var(predictions)        \n",
    "        variance_values.append(var)\n",
    "        mse_values.append(mse)   \n",
    "    \n",
    "    avg_mse = np.mean(mse_values)\n",
    "    avg_var = np.mean(variance_values)\n",
    "    return(avg_mse, avg_var)\n",
    "        \n",
    "two_mse1, two_var1 = train_and_cross_val(\n",
    "    [\"cylinders\", \"displacement\"])\n",
    "three_mse1, three_var1 = train_and_cross_val(\n",
    "    [\"cylinders\", \"displacement\", \"horsepower\"])\n",
    "four_mse1, four_var1 = train_and_cross_val(\n",
    "    [\"cylinders\", \"displacement\", \"horsepower\", \"weight\"])\n",
    "five_mse1, five_var1 = train_and_cross_val(\n",
    "    [\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \n",
    "     \"acceleration\"])\n",
    "six_mse1, six_var1 = train_and_cross_val(\n",
    "    [\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \n",
    "     \"acceleration\", \"model year\"])\n",
    "seven_mse1, seven_var1 = train_and_cross_val(\n",
    "    [\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \n",
    "     \"acceleration\",\"model year\", \"origin\"])\n",
    "\n",
    "print(two_mse1, two_var1)\n",
    "print(three_mse1, three_var1)\n",
    "print(four_mse1, four_var1)\n",
    "print(five_mse1, five_var1)\n",
    "print(six_mse1, six_var1)\n",
    "print(seven_mse1, seven_var1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During cross validation, the more features we added to the model, the lower the mean squared error got. This is a good sign and indicates that the model generalizes well to new data it wasn't trained on. As the mean squared error value went down, however, the variance of the predictions went up. This is to be expected, since the models with lower squared error values had higher model complexity, which tends to be more sensitive to small variations in input values (or high variance).\n",
    "\n",
    "## 5. Plotting Error and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter([2,3,4,5,6,7], [two_mse1, three_mse1, four_mse1, \n",
    "                            five_mse1, six_mse1, seven_mse1], c='red')\n",
    "plt.scatter([2,3,4,5,6,7], [two_var1, three_var1, four_var1, \n",
    "                            five_var1, six_var1, seven_var1], c='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While the higher order multivariate models overfit in relation to the lower order multivariate models, the in-sample error and out-of-sample didn't deviate by much. The best model was around 50% more accurate than the simplest model. On the other hand, the overall variance increased around 25% as we increased the model complexity. This is a really good starting point, but your work is not done! The increased variance with the increased model complexity means that your model will have more unpredictable performance on truly new, unseen data.\n",
    "\n",
    "- If you were working on this problem on a data science team, you'd need to confirm the predictive accuracy of the model using completely new, unobserved data (e.g. maybe from cars from later years). Since often you can't wait until a model is deployed in the wild to know how well it works, the exploration we did in this mission helps you approximate a model's real world performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
